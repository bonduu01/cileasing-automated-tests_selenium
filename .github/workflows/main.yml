name: Selenium Tests with Allure Reports

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run tests daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      test_suite:
        description: 'Test Suite to Run'
        required: true
        default: 'all'
        type: choice
        options:
          - all
          - smoke
          - login
          - regression

permissions:
  contents: write
  pages: write
  id-token: write

env:
  PYTHON_VERSION: '3.11'
  ALLURE_VERSION: '2.30.0'

jobs:
  # Job 1: Run Smoke Tests
  smoke-tests:
    name: Smoke Tests
    runs-on: ubuntu-latest
    if: github.event.inputs.test_suite == 'smoke' || github.event.inputs.test_suite == 'all' || github.event_name != 'workflow_dispatch'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Set up Chrome
        uses: browser-actions/setup-chrome@latest
        with:
          chrome-version: stable

      - name: Create directories
        run: |
          mkdir -p screenshots
          mkdir -p allure-results

      - name: Run Smoke Tests
        id: smoke_tests
        continue-on-error: false  # Changed: Will fail on import errors
        env:
          TEST_USERNAME: ${{ secrets.TEST_USERNAME }}
          TEST_PASSWORD: ${{ secrets.TEST_PASSWORD }}
          HEADLESS: true
          TEST_ENV: ci
        run: |
          set +e  # Don't exit immediately on error
          
          # Run tests and capture exit code
          pytest tests_pages/ -m smoke \
            --alluredir=allure-results \
            --clean-alluredir \
            -v \
            --tb=short \
            --junit-xml=junit-smoke.xml
          
          TEST_EXIT_CODE=$?
          
          # Check for critical errors (exit codes that indicate setup/import failures)
          if [ $TEST_EXIT_CODE -eq 4 ]; then
            echo "âŒ FATAL: Pytest collection failed (import error, syntax error, etc.)"
            echo "This indicates a problem with test files or dependencies."
            exit 1
          elif [ $TEST_EXIT_CODE -eq 3 ]; then
            echo "âŒ FATAL: Internal pytest error"
            exit 1
          elif [ $TEST_EXIT_CODE -eq 2 ]; then
            echo "âš ï¸ WARNING: Tests interrupted by user or system"
            exit $TEST_EXIT_CODE
          elif [ $TEST_EXIT_CODE -eq 1 ]; then
            echo "âš ï¸ Some tests failed (this is acceptable for reporting)"
            # Don't exit - we want to generate report even if tests fail
            exit 0
          elif [ $TEST_EXIT_CODE -eq 5 ]; then
            echo "âš ï¸ No tests collected"
            echo "Check if:"
            echo "  1. Tests have @pytest.mark.smoke decorator"
            echo "  2. Test files exist in tests_pages/"
            echo "  3. Test file names start with 'test_'"
            exit 1
          else
            echo "âœ… Tests completed successfully"
            exit 0
          fi

      - name: Upload Smoke Test Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: smoke-test-results
          path: |
            allure-results/
            screenshots/
            junit-smoke.xml
          retention-days: 30

  # Job 2: Run Login Tests
  login-tests:
    name: Login Tests
    runs-on: ubuntu-latest
    if: github.event.inputs.test_suite == 'login' || github.event.inputs.test_suite == 'all' || github.event_name != 'workflow_dispatch'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Set up Chrome
        uses: browser-actions/setup-chrome@latest
        with:
          chrome-version: stable

      - name: Create directories
        run: |
          mkdir -p screenshots
          mkdir -p allure-results

      - name: Run Login Tests
        id: login_tests
        continue-on-error: false  # Changed: Will fail on import errors
        env:
          TEST_USERNAME: ${{ secrets.TEST_USERNAME }}
          TEST_PASSWORD: ${{ secrets.TEST_PASSWORD }}
          HEADLESS: true
          TEST_ENV: ci
        run: |
          set +e
          
          pytest tests_pages/test_user_logins.py \
            --alluredir=allure-results \
            --clean-alluredir \
            -v \
            --tb=short \
            --junit-xml=junit-login.xml
          
          TEST_EXIT_CODE=$?
          
          if [ $TEST_EXIT_CODE -eq 4 ]; then
            echo "âŒ FATAL: Pytest collection failed (import/syntax error)"
            exit 1
          elif [ $TEST_EXIT_CODE -eq 3 ]; then
            echo "âŒ FATAL: Internal pytest error"
            exit 1
          elif [ $TEST_EXIT_CODE -eq 2 ]; then
            echo "âš ï¸ WARNING: Tests interrupted"
            exit $TEST_EXIT_CODE
          elif [ $TEST_EXIT_CODE -eq 1 ]; then
            echo "âš ï¸ Some tests failed (acceptable for reporting)"
            exit 0
          elif [ $TEST_EXIT_CODE -eq 5 ]; then
            echo "âš ï¸ No tests collected"
            exit 1
          else
            echo "âœ… Tests completed successfully"
            exit 0
          fi

      - name: Upload Login Test Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: login-test-results
          path: |
            allure-results/
            screenshots/
            junit-login.xml
          retention-days: 30

  # Job 3: Run Regression Tests
  regression-tests:
    name: Regression Tests
    runs-on: ubuntu-latest
    if: github.event.inputs.test_suite == 'regression' || github.event.inputs.test_suite == 'all' || github.event_name != 'workflow_dispatch'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Set up Chrome
        uses: browser-actions/setup-chrome@latest
        with:
          chrome-version: stable

      - name: Create directories
        run: |
          mkdir -p screenshots
          mkdir -p allure-results

      - name: Run Regression Tests
        id: regression_tests
        continue-on-error: false  # Changed: Will fail on import errors
        env:
          TEST_USERNAME: ${{ secrets.TEST_USERNAME }}
          TEST_PASSWORD: ${{ secrets.TEST_PASSWORD }}
          HEADLESS: true
          TEST_ENV: ci
        run: |
          set +e
          
          pytest tests_pages/ -m regression \
            --alluredir=allure-results \
            --clean-alluredir \
            -v \
            --tb=short \
            --junit-xml=junit-regression.xml
          
          TEST_EXIT_CODE=$?
          
          if [ $TEST_EXIT_CODE -eq 4 ]; then
            echo "âŒ FATAL: Pytest collection failed (import/syntax error)"
            exit 1
          elif [ $TEST_EXIT_CODE -eq 3 ]; then
            echo "âŒ FATAL: Internal pytest error"
            exit 1
          elif [ $TEST_EXIT_CODE -eq 2 ]; then
            echo "âš ï¸ WARNING: Tests interrupted"
            exit $TEST_EXIT_CODE
          elif [ $TEST_EXIT_CODE -eq 1 ]; then
            echo "âš ï¸ Some tests failed (acceptable for reporting)"
            exit 0
          elif [ $TEST_EXIT_CODE -eq 5 ]; then
            echo "âš ï¸ No tests collected"
            exit 1
          else
            echo "âœ… Tests completed successfully"
            exit 0
          fi

      - name: Upload Regression Test Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: regression-test-results
          path: |
            allure-results/
            screenshots/
            junit-regression.xml
          retention-days: 30

  # Job 4: Generate and Deploy Allure Report
  generate-report:
    name: Generate Allure Report
    runs-on: ubuntu-latest
    needs: [smoke-tests, login-tests, regression-tests]
    if: always()  # Still generate report even if some tests failed (but not if setup failed)

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Check if any tests ran
        id: check_tests
        run: |
          # Check if at least one test job succeeded or had test failures (not setup failures)
          if [ "${{ needs.smoke-tests.result }}" == "success" ] || \
             [ "${{ needs.login-tests.result }}" == "success" ] || \
             [ "${{ needs.regression-tests.result }}" == "success" ]; then
            echo "has_results=true" >> $GITHUB_OUTPUT
            echo "âœ… At least one test suite ran successfully"
          else
            echo "has_results=false" >> $GITHUB_OUTPUT
            echo "âŒ All test suites failed during setup/collection"
            echo "Cannot generate report - no valid test results"
          fi

      - name: Download all test results
        if: steps.check_tests.outputs.has_results == 'true'
        uses: actions/download-artifact@v4
        with:
          path: all-results

      - name: Debug - Show downloaded artifacts
        if: steps.check_tests.outputs.has_results == 'true'
        run: |
          echo "=== Downloaded Artifacts Structure ==="
          ls -R all-results/
          echo ""
          echo "=== Searching for allure-results directories ==="
          find all-results -type d -name "allure-results"
          echo ""
          echo "=== Searching for JSON result files ==="
          find all-results -name "*.json" -type f

      - name: Merge Allure Results
        if: steps.check_tests.outputs.has_results == 'true'
        run: |
          mkdir -p allure-results
          echo "Merging allure results from all test suites..."
          
          # Copy all files from allure-results directories
          find all-results -type d -name "allure-results" | while read dir; do
            echo "Copying from: $dir"
            cp -r "$dir"/* allure-results/ 2>/dev/null || true
          done
          
          # Also try direct path copying (backup method)
          cp -r all-results/smoke-test-results/allure-results/* allure-results/ 2>/dev/null || true
          cp -r all-results/login-test-results/allure-results/* allure-results/ 2>/dev/null || true
          cp -r all-results/regression-test-results/allure-results/* allure-results/ 2>/dev/null || true
          
          echo ""
          echo "=== Merged Results ==="
          ls -lah allure-results/
          echo ""
          echo "Total files: $(find allure-results -type f | wc -l)"
          echo "JSON result files: $(find allure-results -name "*-result.json" | wc -l)"
          echo "JSON container files: $(find allure-results -name "*-container.json" | wc -l)"
          echo "Screenshots: $(find allure-results -name "*.png" | wc -l)"
          
          # Create environment properties
          cat > allure-results/environment.properties << EOF
          Browser=Chrome (Headless)
          Engineer= Peter Molokwu
          Environment=Staging
          Python.Version=3.11
          Platform=Ubuntu Latest
          Test.Framework=Pytest
          Build.Number=${{ github.run_number }}
          Commit=${{ github.sha }}
          Branch=${{ github.ref_name }}
          EOF
          
          # Check if we have any test results
          result_count=$(find allure-results -name "*-result.json" | wc -l)
          if [ $result_count -eq 0 ]; then
            echo "âŒ ERROR: No test result JSON files found!"
            echo "Tests did not generate Allure results."
            echo "This usually means:"
            echo "  1. Tests are not marked with pytest markers"
            echo "  2. allure-pytest is not installed"
            echo "  3. Tests failed during collection phase"
            exit 1
          else
            echo "âœ… SUCCESS: Found $result_count test result files"
          fi

      - name: Get Allure history from gh-pages
        if: steps.check_tests.outputs.has_results == 'true'
        continue-on-error: true
        run: |
          echo "Attempting to fetch allure history..."
          
          if git ls-remote --exit-code --heads origin gh-pages; then
            echo "gh-pages branch exists, fetching history..."
            git fetch origin gh-pages:gh-pages
            git checkout gh-pages
            
            if [ -d "allure-history" ]; then
              echo "Found allure-history directory"
              mkdir -p /tmp/allure-history
              cp -r allure-history/* /tmp/allure-history/ 2>/dev/null || true
              echo "History backed up to /tmp/allure-history"
            else
              echo "No allure-history directory found in gh-pages"
            fi
            
            git checkout -
          else
            echo "gh-pages branch does not exist yet (first run)"
          fi

      - name: Install Allure
        if: steps.check_tests.outputs.has_results == 'true'
        run: |
          echo "Installing Allure ${ALLURE_VERSION}..."
          wget -q https://github.com/allure-framework/allure2/releases/download/${ALLURE_VERSION}/allure-${ALLURE_VERSION}.tgz
          tar -zxf allure-${ALLURE_VERSION}.tgz
          sudo mv allure-${ALLURE_VERSION} /opt/allure
          sudo ln -s /opt/allure/bin/allure /usr/bin/allure
          allure --version

      - name: Restore Allure history
        if: steps.check_tests.outputs.has_results == 'true'
        continue-on-error: true
        run: |
          if [ -d "/tmp/allure-history" ]; then
            echo "Restoring allure history..."
            mkdir -p allure-results/history
            cp -r /tmp/allure-history/* allure-results/history/ 2>/dev/null || true
            echo "History restored"
          else
            echo "No history to restore (first run or no previous history)"
          fi

      - name: Generate Allure Report
        if: steps.check_tests.outputs.has_results == 'true'
        run: |
          echo "Generating Allure report..."
          allure generate allure-results -o allure-report --clean
          echo "Report generated successfully"
          ls -la allure-report/

      - name: Prepare deployment directory
        if: steps.check_tests.outputs.has_results == 'true'
        run: |
          mkdir -p gh-pages-deploy
          
          # Copy the report
          cp -r allure-report/* gh-pages-deploy/
          
          # Save history for next run
          if [ -d "allure-report/history" ]; then
            mkdir -p gh-pages-deploy/allure-history
            cp -r allure-report/history/* gh-pages-deploy/allure-history/
            echo "History saved for next run"
          fi
          
          echo "Deployment directory prepared"
          ls -la gh-pages-deploy/

      - name: Deploy to GitHub Pages
        if: steps.check_tests.outputs.has_results == 'true'
        uses: peaceiris/actions-gh-pages@v4
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_branch: gh-pages
          publish_dir: ./gh-pages-deploy
          keep_files: false
          enable_jekyll: false
          user_name: 'github-actions[bot]'
          user_email: 'github-actions[bot]@users.noreply.github.com'
          commit_message: 'Deploy Allure report - Build ${{ github.run_number }}'

      - name: Report generation failed
        if: steps.check_tests.outputs.has_results == 'false'
        run: |
          echo "### âŒ Report Generation Skipped" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "All test suites failed during setup or collection phase." >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Common causes:**" >> $GITHUB_STEP_SUMMARY
          echo "- Import errors in test files" >> $GITHUB_STEP_SUMMARY
          echo "- Missing dependencies" >> $GITHUB_STEP_SUMMARY
          echo "- Syntax errors" >> $GITHUB_STEP_SUMMARY
          echo "- Missing test markers" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Check the test job logs for details." >> $GITHUB_STEP_SUMMARY

      - name: Add report link to summary
        if: steps.check_tests.outputs.has_results == 'true'
        run: |
          echo "### ðŸ“Š Test Report" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ðŸ”— [View Allure Report](https://${{ github.repository_owner }}.github.io/${{ github.event.repository.name }})" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "â³ Report will be available in 1-2 minutes after deployment completes." >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "---" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Build:** #${{ github.run_number }}" >> $GITHUB_STEP_SUMMARY
          echo "**Commit:** ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY

  # Job 5: Notify Results
  notify-results:
    name: Test Results Summary
    runs-on: ubuntu-latest
    needs: [smoke-tests, login-tests, regression-tests, generate-report]
    if: always()

    steps:
      - name: Generate Summary
        run: |
          echo "# ðŸ§ª Test Execution Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Job Status" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Check individual job results
          if [ "${{ needs.smoke-tests.result }}" == "success" ]; then
            echo "### âœ… Smoke Tests: PASSED" >> $GITHUB_STEP_SUMMARY
          elif [ "${{ needs.smoke-tests.result }}" == "failure" ]; then
            echo "### âŒ Smoke Tests: FAILED (Setup/Import Error)" >> $GITHUB_STEP_SUMMARY
          elif [ "${{ needs.smoke-tests.result }}" == "skipped" ]; then
            echo "### â­ï¸ Smoke Tests: SKIPPED" >> $GITHUB_STEP_SUMMARY
          fi
          
          if [ "${{ needs.login-tests.result }}" == "success" ]; then
            echo "### âœ… Login Tests: PASSED" >> $GITHUB_STEP_SUMMARY
          elif [ "${{ needs.login-tests.result }}" == "failure" ]; then
            echo "### âŒ Login Tests: FAILED (Setup/Import Error)" >> $GITHUB_STEP_SUMMARY
          elif [ "${{ needs.login-tests.result }}" == "skipped" ]; then
            echo "### â­ï¸ Login Tests: SKIPPED" >> $GITHUB_STEP_SUMMARY
          fi
          
          if [ "${{ needs.regression-tests.result }}" == "success" ]; then
            echo "### âœ… Regression Tests: PASSED" >> $GITHUB_STEP_SUMMARY
          elif [ "${{ needs.regression-tests.result }}" == "failure" ]; then
            echo "### âŒ Regression Tests: FAILED (Setup/Import Error)" >> $GITHUB_STEP_SUMMARY
          elif [ "${{ needs.regression-tests.result }}" == "skipped" ]; then
            echo "### â­ï¸ Regression Tests: SKIPPED" >> $GITHUB_STEP_SUMMARY
          fi
          
          if [ "${{ needs.generate-report.result }}" == "success" ]; then
            echo "### âœ… Report Generation: SUCCESS" >> $GITHUB_STEP_SUMMARY
          elif [ "${{ needs.generate-report.result }}" == "failure" ]; then
            echo "### âŒ Report Generation: FAILED" >> $GITHUB_STEP_SUMMARY
          elif [ "${{ needs.generate-report.result }}" == "skipped" ]; then
            echo "### â­ï¸ Report Generation: SKIPPED" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## ðŸ“Š Detailed Reports" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ "${{ needs.generate-report.result }}" == "success" ]; then
            echo "ðŸ”— [View Full Allure Report](https://${{ github.repository_owner }}.github.io/${{ github.event.repository.name }})" >> $GITHUB_STEP_SUMMARY
          else
            echo "âŒ Report not available (check logs for errors)" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "---" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Build:** #${{ github.run_number }}" >> $GITHUB_STEP_SUMMARY
          echo "**Commit:** ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
          echo "**Branch:** ${{ github.ref_name }}" >> $GITHUB_STEP_SUMMARY
          echo "**Triggered by:** ${{ github.actor }}" >> $GITHUB_STEP_SUMMARY